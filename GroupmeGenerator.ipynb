{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroupmeGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Directions\n",
        "\n",
        "1. Go to GroupMe and download your data ([Instructions](https://support.microsoft.com/en-us/office/how-do-i-export-my-groupme-data-1f6875bf-7871-4ade-8608-4c606cd5f518)). This will give you a zip file.\n",
        "2. Upload the zip file to Colab using the \"Files\" tab.\n",
        "3. Connect to a GPU runtime ([Instructions](https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm)).\n",
        "3. Run the cells in this notebook, in order, following any instructions as you go."
      ],
      "metadata": {
        "id": "Y3DKAC8_VKIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "D7TTNc8_HQSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json, pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "nwrVQUxpcETh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "z1wSF0pAHtUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import pipeline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "EruyrQzkBRvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "Xa3AJeXJbcyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change this file to whatever your downloaded groupme data is"
      ],
      "metadata": {
        "id": "CiDyLsSVVSjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 00001.zip"
      ],
      "metadata": {
        "id": "gB4sjGQWeXF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change this the id of the groupme you want (it should be the name of the file in the unzipped groupme data)"
      ],
      "metadata": {
        "id": "PQcOijOaVenQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groupme_id = '60588753'"
      ],
      "metadata": {
        "id": "8P7go4BV0GHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = None\n",
        "conversation = None"
      ],
      "metadata": {
        "id": "HnJ9ZvbHey4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'/content/{groupme_id}/message.json') as f:\n",
        "  messages = json.load(f)\n",
        "\n",
        "with open(f'/content/{groupme_id}/conversation.json') as f:\n",
        "  conversation = json.load(f)"
      ],
      "metadata": {
        "id": "ZKYxgWu9cJaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you did the above steps correctly, the cell below should output the name of your GroupMe."
      ],
      "metadata": {
        "id": "3ZgoMztgVsOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groupme_name = conversation['name'].replace('/', '')\n",
        "groupme_name"
      ],
      "metadata": {
        "id": "Ogqkg-7aH_oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this should output the total number of messages in the group"
      ],
      "metadata": {
        "id": "QaJopn2zV6f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P8k4sCdZuu2"
      },
      "outputs": [],
      "source": [
        "print(f'Number of messages: {len(messages)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id_to_name_map = {member['user_id']: member['name'] for member in conversation['members']}"
      ],
      "metadata": {
        "id": "JnVE-aDZgB7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows the users and their ids"
      ],
      "metadata": {
        "id": "R9WSeg3iWYrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id_to_name_map"
      ],
      "metadata": {
        "id": "HS94Tk3Ohw8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_name(user_id, override_name):\n",
        "  if user_id in user_id_to_name_map:\n",
        "    return f'{user_id_to_name_map[user_id]}'\n",
        "  return f'{override_name}'"
      ],
      "metadata": {
        "id": "suJ3cASn1evl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_message(user_id, text, override_name):\n",
        "  if user_id == 'system':\n",
        "    return text\n",
        "  return f'{format_name(user_id, override_name)}: {text}'"
      ],
      "metadata": {
        "id": "KSp51IQgrysj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_messages = []\n",
        "\n",
        "for message in messages:\n",
        "  cleaned_message = message['text']\n",
        "  if message['attachments']:\n",
        "    for attachment in message['attachments']:\n",
        "      if attachment['type'] == 'mentions':\n",
        "        new_text = cleaned_message\n",
        "        offset = 0\n",
        "        for (user_id, loc) in zip(attachment['user_ids'], attachment['loci']):\n",
        "          try:\n",
        "            start, length = loc\n",
        "            finish = start + length\n",
        "            name = user_id_to_name_map[user_id]\n",
        "            new_text = new_text[:start + offset] + '@' + name + new_text[finish + offset:]\n",
        "            offset += len(name) - (finish - start) + 1\n",
        "          except:\n",
        "            pass\n",
        "        cleaned_message = new_text\n",
        "      elif attachment['type'] in ['image', 'linked_image']:\n",
        "        cleaned_messages += [{'text': f'{format_name(message[\"user_id\"], message[\"name\"])} shared an image.', 'time': message['created_at']}]\n",
        "      elif attachment['type'] == 'video':\n",
        "        cleaned_messages += [{'text': f'{format_name(message[\"user_id\"], message[\"name\"])} shared a video.', 'time': message['created_at']}]\n",
        "      elif attachment['type'] == 'poll':\n",
        "        cleaned_messages += [{'text': f'{format_name(message[\"user_id\"], message[\"name\"])} created a poll.', 'time': message['created_at']}]\n",
        "      elif attachment['type'] == 'file':\n",
        "        cleaned_messages += [{'text': f'{format_name(message[\"user_id\"], message[\"name\"])} shared a file.', 'time': message['created_at']}]\n",
        "\n",
        "  if cleaned_message and cleaned_message != 'None':\n",
        "    cleaned_message.encode('ascii', 'ignore')\n",
        "    cleaned_message = cleaned_message.replace('ï¿½', '')\n",
        "    cleaned_messages += [{'text': format_message(message['user_id'], cleaned_message, message['name']), 'time': message['created_at']}]"
      ],
      "metadata": {
        "id": "8suFtrNKgdP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_messages = sorted(cleaned_messages, key=lambda m: m['time'])"
      ],
      "metadata": {
        "id": "gnwU3DY_tvEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_messages[1000:1010]"
      ],
      "metadata": {
        "id": "bDIYLhBt3WRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_messages = [{**message, **{'time_delta': 0, 'tokenized_length': len(word_tokenize(message['text']))}} for message in cleaned_messages]"
      ],
      "metadata": {
        "id": "HU6Hqq78Jsq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cleaned_messages) - 1):\n",
        "  cleaned_messages[i]['time_delta'] = cleaned_messages[i + 1]['time'] - cleaned_messages[i]['time']"
      ],
      "metadata": {
        "id": "xCVEq3LKK6Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_messages[100:110]"
      ],
      "metadata": {
        "id": "ysouBSpdLQHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_length(messages):\n",
        "  return sum([message['tokenized_length'] for message in messages]) + len(messages) - 1"
      ],
      "metadata": {
        "id": "l0Us4nO1QDMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_group = {\"messages\": cleaned_messages, \"total_length\": group_length(cleaned_messages)}"
      ],
      "metadata": {
        "id": "4_9X3NqePoyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_max_size = 325\n",
        "absolute_max_size = 750"
      ],
      "metadata": {
        "id": "gH0XE53yQTpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_messages(group, debug=False):\n",
        "  \"\"\"\n",
        "  Recursively groups messages until messages are of a set length\n",
        "  \"\"\"\n",
        "  if group['total_length'] < absolute_max_size:\n",
        "    return [group]\n",
        "  \n",
        "  running_size = group['messages'][0]['tokenized_length']\n",
        "\n",
        "  best_break_i = 0\n",
        "  best_score = -1\n",
        "  best_size = running_size\n",
        "\n",
        "  for i in range(1, len(group['messages'])):\n",
        "    if group['messages'][i]['time_delta'] != 0:\n",
        "      # score is log(time_delta) * (1 if min_new_group_size > target_max_size else min_new_group_size / target_max_size)\n",
        "      min_new_group_size = min(running_size, group['total_length'] - running_size)\n",
        "      score = math.log(group['messages'][i]['time_delta'])\n",
        "\n",
        "      if min_new_group_size < target_max_size:\n",
        "        score *= (min_new_group_size / target_max_size)\n",
        "\n",
        "      if score > best_score:\n",
        "        best_score = score\n",
        "        best_break_i = i\n",
        "        best_size = running_size\n",
        "\n",
        "    running_size += group['messages'][i]['tokenized_length'] + 1\n",
        "\n",
        "  if best_score < 0:\n",
        "    print(group)\n",
        "    raise Exception(\"Invalid score\")\n",
        "\n",
        "  left_group = {'messages': group['messages'][:best_break_i], 'total_length': best_size}\n",
        "  right_group = {'messages': group['messages'][best_break_i:], 'total_length': group['total_length'] - best_size - 1}\n",
        "\n",
        "  if debug:\n",
        "    assert(left_group['total_length'] + right_group['total_length'] + 1 == group['total_length'])\n",
        "    assert(group_length(left_group['messages']) == left_group['total_length']), f\"{group_length(left_group['messages'])} != {left_group['total_length']}\"\n",
        "    assert(group_length(right_group['messages']) == right_group['total_length']), f\"{group_length(right_group['messages'])} != {right_group['total_length']}\"\n",
        "\n",
        "  left_group_rec = group_messages(left_group)\n",
        "  right_group_rec = group_messages(right_group)\n",
        "\n",
        "  #if debug:\n",
        "  #  assert(group_length(left_group_rec))\n",
        "\n",
        "  return left_group_rec + right_group_rec\n"
      ],
      "metadata": {
        "id": "HUQHUUSiPPwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_messages = group_messages(initial_group, debug=True)"
      ],
      "metadata": {
        "id": "6KLwiIdFWKa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_messages[10]"
      ],
      "metadata": {
        "id": "o9FLXf8UaDMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(grouped_messages))"
      ],
      "metadata": {
        "id": "55Bmlr3M4bm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These messages are just sanity checks to tell if the GroupMe has successfully been split up into individual conversations for training."
      ],
      "metadata": {
        "id": "3WgECH0zWukh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [group['total_length'] for group in grouped_messages]\n",
        "print('Max length, Min length, Avg length')\n",
        "print(max(lengths), min(lengths), sum(lengths) / len(grouped_messages))"
      ],
      "metadata": {
        "id": "91oCVMNe4tT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histogram = {}\n",
        "for length in lengths:\n",
        "  if length not in histogram:\n",
        "    histogram[length] = 1\n",
        "  else:\n",
        "    histogram[length] += 1"
      ],
      "metadata": {
        "id": "Rid0XfrF5OR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(histogram.keys(), histogram.values())"
      ],
      "metadata": {
        "id": "aLBfyDIt6AJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = ['\\n'.join([message['text'] for message in group['messages']]) for group in grouped_messages]"
      ],
      "metadata": {
        "id": "bBEttBU9a8BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[50]"
      ],
      "metadata": {
        "id": "glr9_9qYbYok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This saves the formatted training data to a file. The next step section will start with loading from that same file, so if you ever want to train again, you can skip to this part and just upload the saved training data. Make sure to download the file created if you think you will need to do this, or move it to google drive (Colab only keeps these files temporarily). "
      ],
      "metadata": {
        "id": "r0N0lmUbXRG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{groupme_name}.pkl', \"wb\") as f:\n",
        "  pickle.dump(raw_data, f)"
      ],
      "metadata": {
        "id": "LTs_fT9ebodo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "qFvZAB-Vc0Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If loading from a file, uncomment the code below and replace 'YOUR GROUPME NAME' with the name of the groupme training data you want to load from."
      ],
      "metadata": {
        "id": "o0JBF9oCX5Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# groupme_name = 'YOUR GROUPME NAME'"
      ],
      "metadata": {
        "id": "L44X6XUSX1pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset = []"
      ],
      "metadata": {
        "id": "tcTuP7-cdMUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'/content/{groupme_name}.pkl', \"rb\") as f:\n",
        "  text_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "4X9i23Lec2I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset[50]"
      ],
      "metadata": {
        "id": "OZnKhrOrdR8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium"
      ],
      "metadata": {
        "id": "l3R_cm9aeYbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]   "
      ],
      "metadata": {
        "id": "6N0SGLl4dhLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPT2Dataset(text_dataset, tokenizer, max_length=768)"
      ],
      "metadata": {
        "id": "5GtAQGAQeOlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation sets\n",
        "train_size = int(0.95 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "id": "SdLyXshRfmqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "38XhG-tM-rGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "metadata": {
        "id": "pvZx-4xKc7V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0VoboyQ2An9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "LDI0hk_TBcXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "N5C2cYS0gAnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "metadata": {
        "id": "-uCvuS0fgNZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "eVRSNN3ygYud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "gyVh4nLLgbz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what actually trains the model. It takes 5 epochs, and the total training time can range from a few minutes to an hour+. Longest it has taken me is about 45 minutes, but it scales with the size of your GroupMe."
      ],
      "metadata": {
        "id": "s6zKT5y8YSbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "id": "bmQX3p3XgpmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "7kj8QyonkfhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the \"Training\" line goes down. Expected values are around 1.0-3.0"
      ],
      "metadata": {
        "id": "i4Seo3_CYvEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rWmRL9j-knPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This saves the model to a local directory, 'model_save'\n",
        "\n",
        "I highly recommend saving the model if you plan on querying this again - otherwise you will have to train again."
      ],
      "metadata": {
        "id": "v1y8KCllY4Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "id": "qG8a_m9Rkzjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some storage info about the model that was just saved."
      ],
      "metadata": {
        "id": "D8zO5KIYZImJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "metadata": {
        "id": "q2gS03Olk4Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "oO_D3Bt8k_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important: This will move the directory you just made into Google Drive, under a folder named GroupmeGeneratorData (you might need to create that folder). Before you run this, be sure that colab has access to your Google Drive (Files => Mount to Drive).\n",
        "\n",
        "You can change 'YOUR_GROUPME_NAME' to whatever you want, but make sure it matches the name in the next step."
      ],
      "metadata": {
        "id": "W-vt_EkKZVIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ /content/drive/MyDrive/GroupmeGeneratorData/YOUR_GROUPME_NAME"
      ],
      "metadata": {
        "id": "YYoCaGBElJxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "pJO8bpdgmBH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loads the model from the stored Google Drive directory. If you made it to this step, you can return at any point by simply:\n",
        "1.   Rerunning the \"Imports\" section\n",
        "2.   Running the cell below\n",
        "\n",
        "No need to touch the above sections once your model is trained!"
      ],
      "metadata": {
        "id": "L0uxxPYIaC4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rRudyStreetBets, MikeyMicah, SuckDuckBills\n",
        "output_dir = '/content/drive/MyDrive/GroupmeGeneratorData/YOUR_GROUPME_NAME'\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)\n",
        "print(f\"Model loaded from {output_dir}\")"
      ],
      "metadata": {
        "id": "Ll8IXZWQVzAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator Directions**\n",
        "\n",
        "To generate text from the model, run the cell below.\n",
        "\n",
        "The \"prompt\" is how you control what is being generated. **Make sure that your prompt always starts with <|startoftext|>**. If the prompt is just <|startoftext|>, it will generate random, unprompted conversations. If you supply it more (e.g. 'Person Name: It is my opinion that') then it will start the generated conversations with that message. \n",
        "\n",
        "The model will return three sequences, you can change this to more or less by adjusting num_return_sequences."
      ],
      "metadata": {
        "id": "QTIymotraZFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|> Person Name: It is my opinion that\" # Change this!\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i + 1, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "6Lm72KZal-l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Source for GPT-2 Fine Tuning](https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=v4XhewaV93-_)"
      ],
      "metadata": {
        "id": "uwckWIJscmue"
      }
    }
  ]
}